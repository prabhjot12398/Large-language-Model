{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68b086d1-0b1d-44cd-b8c1-b885c58e7f0a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import torch.nn as nn\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "073e06b7-8918-4bd3-8287-6718cc95665c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 274,  462,  294,  -64, -439,  373])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randint = torch.randint(-500 , 500 ,(6,))\n",
    "randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4027efa-9bb5-4334-b338-d02f3905a475",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.2000],\n",
       "        [0.3000, 0.4000],\n",
       "        [1.0000, 6.0000]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([[0.1,0.2],[0.3,0.4],[1,6]])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d7ae4dd-6230-40c7-94c5-a79595ff81ab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#these are Floating point numbers\n",
    "zeros = torch.zeros(2,3)\n",
    "zeros\n",
    "ones = torch.ones(5,4)\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f10a58c-0d1d-4e19-a6be-c520dc7e8f5c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arange = torch.arange(6)\n",
    "arange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cb05cb4-e551-4807-8d80-33ff0fcbad89",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.0000,  7.5000, 10.0000])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linspace = torch.linspace(start = 5, end = 10, steps = 3)\n",
    "linspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a20b8d2f-90db-4894-a4ab-bf3d4ef35a29",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e-10, 1.0000e+00, 1.0000e+10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logspace = torch.logspace(-10 , 10 ,3)\n",
    "logspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23e71e72-11d3-4a17-b796-ab644d354a05",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eye = torch.eye(6)\n",
    "eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df1ce0e2-e8d2-4ab9-8c07-52594001b65d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0000\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "zeros = torch.zeros(1,1)\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"{elapsed_time:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b967109a-79c5-4eac-92c9-ec0b81e7a057",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.044879\n",
      " 0.116092\n"
     ]
    }
   ],
   "source": [
    "#Comparing running time between Gpu and Cpu\n",
    "torch_rand1 = torch.rand(100 , 100 , 100 , 100).to(device)\n",
    "torch_rand2 = torch.rand(100 , 100 , 100 , 100).to(device)\n",
    "np_array1 = torch.rand(100 , 100 , 100 , 100)\n",
    "np_array2 = torch.rand(100 , 100 , 100 , 100)\n",
    "\n",
    "start_time = time.time()\n",
    "rand = (torch_rand1 @ torch_rand2)\n",
    "end_time = time.time()\n",
    "Elapsed_time = end_time - start_time\n",
    "print(f\"{Elapsed_time:9f}\")\n",
    "\n",
    "start_time = time.time()\n",
    "rand = np.multiply(np_array1,np_array2)\n",
    "end_time = time.time()\n",
    "Elapsed_time = end_time - start_time\n",
    "print(f\"{Elapsed_time:9f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a76cc9bf-d86b-43cf-b818-fab24aebde3f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining a probability tensor\n",
    "probabilities = torch.tensor([0.1,0.9])\n",
    "samples = torch.multinomial(probabilities, 10, True)\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e543f7ae-dbc9-42b4-92b9-ded6765e8567",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatinating two tensors into one and this can be used when we are generating text, given a context\n",
    "tensor = torch.tensor([1,2,3,4,5])\n",
    "#dim is a parameter used in the torch.cat function to specify the dimension along which the tensors should be concatenated.\n",
    "outputt = torch.cat((tensor, torch.tensor([5])), dim = 0)         \n",
    "outputt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23acf63d-6e24-4b6e-bb84-67fbac077193",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tril - triangle lower\n",
    "out = torch.tril(torch.ones(5,5))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91cfd2eb-fa95-4cf7-bb44-6c7117d51fff",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [0., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.triu(torch.ones(5,5))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e5ab540-6dda-4064-bbb7-20314b33a51a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.zeros(5,5).masked_fill(torch.tril(torch.ones(5,5))==0,float('-inf'))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fe6da37-1669-4db7-ba53-368eea4c33e8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3bc984d-51d7-4dd2-9391-15945ef31e4c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.zeros(2,3,4)\n",
    "#transposing position of 0th and 2nd position \n",
    "out = input.transpose(0,2)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fda2d56-903f-4da9-bde3-40b8d926249b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [2, 2, 4],\n",
       "        [1, 7, 6]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stacking tensor along new dimension\n",
    "tensor1 = torch.tensor([1,2,3])\n",
    "tensor2 = torch.tensor([2,2,4])\n",
    "tensor3 = torch.tensor([1,7,6])\n",
    "\n",
    "stacked = torch.stack([tensor1,tensor2,tensor3])\n",
    "stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc6e0b54-e960-4c8f-858d-9e00a2255b2f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -2.3803, -11.5240,  -1.5417], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "# Import the neural network module from PyTorch\n",
    "import torch.nn as nn\n",
    "# Create a sample input tensor with three elements, all set to 10.0\n",
    "sample = torch.tensor([10.,10.,10.])\n",
    "# Create a linear transformation layer with 3 inputs and 3 outputs, and no bias term\n",
    "linear = nn.Linear(3,3,bias=False)\n",
    "print(linear(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e3f4c6c-acaf-47fd-8391-82eed457cfe8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0900, 0.2447, 0.6652])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "#create a tensor\n",
    "tensor1 = torch.tensor([1.,2.,3.])\n",
    "#apply Softmax using torch.nn.functional.softmax() e^1,e^2,e^3 where e=2.71\n",
    "softmax_output = F.softmax(tensor1, dim=0)\n",
    "\n",
    "print(softmax_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2fc1dda-cc3e-4300-b1f7-26c0a6b1a94f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 100])\n",
      "tensor([[ 1.7898,  1.0265,  0.7056, -0.0255, -0.6323, -0.8560,  0.3170, -0.0717,\n",
      "          1.0658, -1.2591,  0.3992,  0.3952, -2.2179, -0.9448, -0.6567,  1.4952,\n",
      "          0.8563, -1.3868, -1.0400,  0.5519,  0.9766,  0.0409,  0.0455,  0.3831,\n",
      "          1.2896, -1.1974,  0.0217,  0.0386, -0.2203,  0.1044,  1.3453, -0.7792,\n",
      "          0.3088, -0.4445, -0.4841, -1.5745,  0.9720, -1.2630,  0.2429, -1.1160,\n",
      "          0.4022, -0.5919, -0.0795, -1.1694,  0.2100,  1.6644, -0.4248, -0.4416,\n",
      "          0.6084,  0.6506, -0.7270, -0.5558,  0.8538, -0.1391,  0.8873, -1.5533,\n",
      "          0.4403, -1.1040, -1.8920, -2.4410,  1.4713,  1.3889,  0.4045,  0.1267,\n",
      "         -1.0661, -0.4566,  0.2759,  0.7640, -0.6509,  0.7197, -2.3696,  1.1021,\n",
      "          2.2915, -0.3719, -0.5603,  0.1483,  0.1898,  0.4700, -0.3930, -0.6214,\n",
      "          1.2361,  1.1139,  0.8684,  0.3590,  0.4443, -0.5843, -0.8322,  0.0279,\n",
      "         -0.3309, -0.3410,  0.8427,  0.7752, -0.6399,  0.7618, -0.2264,  1.2131,\n",
      "         -1.0483, -0.5242,  1.0226,  1.1506],\n",
      "        [ 0.1804, -0.2725,  1.3953, -0.6379,  0.0650,  0.7737,  0.8851, -1.5358,\n",
      "         -0.0557,  0.5746, -0.0559, -0.8800,  0.9601,  0.8538,  1.0684,  0.9288,\n",
      "          0.0747,  1.2751,  0.4072,  0.4582, -2.5205,  0.8469,  0.4127, -1.8085,\n",
      "          0.8328, -0.8024, -0.9049, -0.8044,  1.7816, -0.4000, -0.8620, -1.3470,\n",
      "         -0.4031, -1.3022, -0.9430, -1.0900,  2.0288, -0.9920, -0.3274,  2.1257,\n",
      "         -0.3643,  0.6105,  0.1193, -0.3798,  1.4169,  1.0365, -0.7737,  0.1259,\n",
      "          1.7141,  0.1756, -0.2053, -2.9046, -1.1366,  1.0223, -1.6374,  0.8933,\n",
      "          0.6478, -0.8073,  0.3156, -0.4273,  0.1411,  0.6427,  0.9179,  0.5502,\n",
      "         -1.3411, -0.2230, -0.0339, -2.1999, -0.5296,  0.7849, -1.0132, -2.1992,\n",
      "         -0.5185, -0.5198,  1.3443, -1.2235,  0.8861, -1.0651,  0.3408,  0.1763,\n",
      "          0.3280,  0.2714, -0.1613,  0.9030,  1.6133, -0.0579,  1.8926,  0.6666,\n",
      "          1.8963,  0.2553,  1.3211, -0.6352, -1.1528,  1.4740,  0.4829,  0.2450,\n",
      "          0.6285, -1.2638,  1.1203, -1.9611],\n",
      "        [ 0.7849,  0.7855,  0.9555,  0.5153,  0.2899,  0.0420, -0.4907, -0.7398,\n",
      "         -0.5610, -0.5445, -1.0772, -0.0475, -0.0666,  0.1572,  0.5157, -1.1793,\n",
      "          0.0452, -0.5553,  1.0102,  0.8581,  1.1584, -1.1545, -0.1945, -0.7902,\n",
      "         -0.2284,  0.1379, -0.4367, -0.1505,  1.3606, -1.3652, -1.1894, -0.0210,\n",
      "          0.2775,  1.5814, -1.7256, -0.3232,  0.6044,  0.6999,  0.1702, -0.8034,\n",
      "          0.9585, -0.7374, -0.5308, -0.5220,  0.1999,  1.1293,  0.1352, -0.7505,\n",
      "          0.4906,  0.4530,  1.4288, -1.3782, -0.7582,  2.1062, -0.1869,  0.0589,\n",
      "          1.5861, -0.5595, -0.4003,  1.7026,  0.6803,  2.2517, -0.4561,  0.4106,\n",
      "         -0.9849,  1.0034, -1.4076,  1.0872, -1.0527, -0.4159,  0.7544, -2.2930,\n",
      "         -0.1620, -0.7708,  0.6844,  1.3752, -0.3940, -0.2201, -1.1190, -0.1684,\n",
      "         -0.5539,  0.1156, -0.7334,  1.4821,  0.1784, -0.3537, -0.1179, -1.7253,\n",
      "          0.7057,  0.0113,  0.5937,  0.0480, -0.1797, -2.0570, -0.6019, -0.6945,\n",
      "          1.1336, -0.3811, -0.8395, -0.2464],\n",
      "        [-0.6087,  0.8158, -0.0200,  0.5685,  1.0403,  0.0619, -0.3910,  0.9529,\n",
      "          1.6114,  0.7168,  2.3266,  0.3114,  1.3993, -0.4156, -1.8242,  0.0774,\n",
      "         -0.3700,  0.3369, -2.0668,  0.8914,  0.4065,  0.0464, -2.0361,  0.7330,\n",
      "          0.7526,  1.0644,  0.4251,  0.6872,  0.7835, -0.0325,  1.0241, -2.6189,\n",
      "         -0.2816,  1.5081,  0.0979, -1.1159, -1.2348, -0.1302,  0.2350,  0.5992,\n",
      "          0.0847, -0.5106,  0.3798,  0.2550, -0.1528, -0.5630,  0.1474,  1.0793,\n",
      "          0.7015, -1.0105, -0.0758, -0.6620, -0.0561, -1.0389,  0.9714,  0.3069,\n",
      "          0.2673, -0.2250, -0.3969,  0.5023, -1.2326,  1.5797,  0.0635,  0.7164,\n",
      "          0.3752,  0.3214, -2.1825,  0.2671,  1.4049, -2.4479,  1.2493, -0.3425,\n",
      "          2.1305,  1.1224, -0.6996,  0.9900, -0.9300,  0.8219,  0.1487,  1.0673,\n",
      "         -0.2114,  1.9441, -0.9252, -1.4662, -0.1894, -1.7928,  0.8113, -1.2589,\n",
      "          1.1639,  0.1635, -1.3511, -1.8145,  2.2514,  0.6048,  0.4873, -0.8925,\n",
      "         -1.2687,  0.5426, -1.2684, -0.0488]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#initialize an embedding layer\n",
    "vocab_size = 1000\n",
    "embed_dim = 100\n",
    "embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "\n",
    "#create input indices\n",
    "input_indices = torch.LongTensor([1,5,3,2])\n",
    "\n",
    "#apply embedding layer\n",
    "embedded_output = embedding(input_indices)\n",
    "\n",
    "# The output will be a tensor of shape (4, 100), where 4 is the number of inputs\n",
    "# and 100 is the dimensionality of the embedding vectors\n",
    "print(embedded_output.shape)\n",
    "print(embedded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "901874a2-c85c-49bc-ada4-1fcc6379a00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 27,  30,  33],\n",
      "        [ 61,  68,  75],\n",
      "        [ 95, 106, 117]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1,2],[3,4],[5,6]])\n",
    "b = torch.tensor([[7,8,9],[10,11,12]])\n",
    "# print(a @ b)\n",
    "print(torch.matmul(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46481c0-54de-4b7b-9259-126208895bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_64 = torch.randint(1, (3, 2)).float()\n",
    "#type int64\n",
    "float_32 = torch.rand(2,3)\n",
    "#type float32\n",
    "# print(int_64.dtype, float_32.dtype)\n",
    "result = torch.matmul(int_64, float_32)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
